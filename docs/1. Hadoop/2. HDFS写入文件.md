# HDFS写入文件流程
HDFS写文件是整个Hadoop中最为复杂的流程之一。

首先上一段代码，客户端是如何读文件的：
``` java
public static void main(String[] args) throws IOException {
    Configuration conf = new Configuration();
    FileSystem fs = FileSystem.get(conf);
    FSDataOutputStream fsDataOutputStream = fs.create(new Path("/hadoop-learning/novel.txt"));
    IOUtils.copyBytes(System.in, fsDataOutputStream, 4096);
}
```
总体来说，最简单的HDFS写文件大体流程如下：
1. 获取文件系统实例FileSyStem，并通过其create()方法获取文件系统输出流outputStream；
   1. FileSyStem内部封装了一个dfs的客户端，通过通过dfs客户端连接namenode，在namenode上创建文件元数据（没有申请数据块），并获取文件状态FileStatus；
   2. 通过文件状态FileStatus构造文件系统输出流outputStream
2. 通过文件系统输入流outputStream写入数据
   1. 文件系统输出流outputStream内部创建了一个DataStreamer，是一个线程
   2. 线程的首次写入会向namenode申请一个空的数据块，namenode会返回该数据块的LocatedBlock
   3. 然后线程以数据流管道的方式，写入LocatedBlock中的第一个datanode节点，并由列表中前一个datanode将数据传输给后一个
   4. 确认数据包同样以数据流管道的方式，由列表中后一个datanode返回给前一个
   5. 写满一个节点后，向namenode申请一个新的空的数据块，然后重复传输的过程
3. 文件传输完成后，线程会调用namenode的complete方法通知已完成，并关闭输入流
   
## 1.如何获取一个文件的输出流FSDataOutputStream
### 1.1 FileSystem.create()
``` java
public HdfsDataOutputStream create(final Path f, final FsPermission permission, final boolean overwrite, final int bufferSize, final short replication, final long blockSize, final Progressable progress, final InetSocketAddress[] favoredNodes) throws IOException {
    //文件系统读写过程中的一些统计
    this.statistics.incrementWriteOps(1);
    this.storageStatistics.incrementOpCounter(OpType.CREATE);
    //相对路径转换为绝对路径
    Path absF = this.fixRelativePart(f);
    return (HdfsDataOutputStream)(new FileSystemLinkResolver<HdfsDataOutputStream>() {
        //核心方法
        public HdfsDataOutputStream doCall(Path p) throws IOException, UnresolvedLinkException {
            //10个参数，getPathName表示要创建的文件路径，buffersize表示缓冲大小
            //此处的dfs为DFSCLient实例，在DistributedFileSystem的initialize方法中创建
            //通过DFSCLient的create方法构建DFSOutputStream实例
            DFSOutputStream out = DistributedFileSystem.this.dfs.create(DistributedFileSystem.this.getPathName(f), permission, overwrite ? EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE) : EnumSet.of(CreateFlag.CREATE), true, replication, blockSize, progress, bufferSize, (ChecksumOpt)null, favoredNodes);
            //再通过DFSCLient的createWrappedOutputStream方法将DFSOutputStream封装成FSDataOutputStream
            return DistributedFileSystem.this.dfs.createWrappedOutputStream(out, DistributedFileSystem.this.statistics);
        }

        public HdfsDataOutputStream next(FileSystem fs, Path p) throws IOException {
            if (fs instanceof DistributedFileSystem) {
                DistributedFileSystem myDfs = (DistributedFileSystem)fs;
                return myDfs.create(p, permission, overwrite, bufferSize, replication, blockSize, progress, favoredNodes);
            } else {
                throw new UnsupportedOperationException("Cannot create with favoredNodes through a symlink to a non-DistributedFileSystem: " + f + " -> " + p);
            }
        }
    }).resolve(this, absF);
}
```

## 1.2 进入dfs.create()方法
``` java
public DFSOutputStream create(String src, FsPermission permission, EnumSet<CreateFlag> flag, boolean createParent, short replication, long blockSize, Progressable progress, int buffersize, ChecksumOpt checksumOpt, InetSocketAddress[] favoredNodes) throws IOException {
    //checkOpen()方法表示检查文件系统是否已经打开
    this.checkOpen();
    if (permission == null) {
        permission = FsPermission.getFileDefault();
    }

    FsPermission masked = FsCreateModes.applyUMask(permission, this.dfsClientConf.uMask);
    if (LOG.isDebugEnabled()) {
        LOG.debug(src + ": masked=" + masked);
    }

    String[] favoredNodeStrs = null;
    if (favoredNodes != null) {
        favoredNodeStrs = new String[favoredNodes.length];

        for(int i = 0; i < favoredNodes.length; ++i) {
            favoredNodeStrs[i] = favoredNodes[i].getHostName() + ":" + favoredNodes[i].getPort();
        }
    }
    //发现实际是通过DFSOutputStream的newStreamForCreate()方法来获取数据输出流
    DFSOutputStream result = DFSOutputStream.newStreamForCreate(this, src, masked, flag, createParent, replication, blockSize, progress, buffersize, this.dfsClientConf.createChecksum(checksumOpt), favoredNodeStrs);
    //此处开启文件租约
    this.beginFileLease(result.getFileId(), result);
    return result;
}
```

### 1.3 进入DFSOutputStream构造方法newStreamForCreate()
``` java 
static DFSOutputStream newStreamForCreate(DFSClient dfsClient, String src, FsPermission masked, EnumSet<CreateFlag> flag, boolean createParent, short replication, long blockSize, Progressable progress, int buffersize, DataChecksum checksum, String[] favoredNodes) throws IOException {
    TraceScope scope = dfsClient.newPathTraceScope("newStreamForCreate", src);

    try {
        HdfsFileStatus stat = null;
        boolean shouldRetry = true;
        //抛异常尝试重试次数
        int retryCount = 10;

        while(true) {
            if (shouldRetry) {
                shouldRetry = false;

                try {
                    //这里通过DFSClient中nameNode的create()方法，在HDFS文件系统中创建一个文件，并返回文件状态HdfsFileStatus
                    stat = dfsClient.namenode.create(src, masked, dfsClient.clientName, new EnumSetWritable(flag), createParent, replication, blockSize, SUPPORTED_CRYPTO_VERSIONS);
                } catch (RemoteException var21) {
                    IOException e = var21.unwrapRemoteException(new Class[]{AccessControlException.class, DSQuotaExceededException.class, FileAlreadyExistsException.class, FileNotFoundException.class, ParentNotDirectoryException.class, NSQuotaExceededException.class, RetryStartFileException.class, SafeModeException.class, UnresolvedPathException.class, SnapshotAccessControlException.class, UnknownCryptoProtocolVersionException.class});
                    if (e instanceof RetryStartFileException) {
                        if (retryCount <= 0) {
                            throw new IOException("Too many retries because of encryption zone operations", e);
                        }

                        shouldRetry = true;
                        --retryCount;
                        continue;
                    }

                    throw e;
                }
            }

            Preconditions.checkNotNull(stat, "HdfsFileStatus should not be null!");
            //发现，DFSOutputStream输入流对象在此时构造，构造方法需要传入文件路径，文件状态。
            DFSOutputStream out = new DFSOutputStream(dfsClient, src, stat, flag, progress, checksum, favoredNodes);
            //启动数据输出流
            out.start();
            DFSOutputStream var23 = out;
            return var23;
        }
    } finally {
        scope.close();
    }
}
```

DFSClient中nameNode的Create()方法，实际上是调用的是客户端与名字节点间的RPC--ClientProtocol的create()方法，该方法的作用是在NameNode上创建一个空文件，并返回文件状态。

### 1.4 DFSOutputStream构造方法
``` java
private DFSOutputStream(DFSClient dfsClient, String src, HdfsFileStatus stat, EnumSet<CreateFlag> flag, Progressable progress, DataChecksum checksum, String[] favoredNodes) throws IOException {
    this(dfsClient, src, flag, progress, stat, checksum);
    this.shouldSyncBlock = flag.contains(CreateFlag.SYNC_BLOCK);
    // 计算数据包块大小
    // 数据的发送是通过一个个数据包发送
    this.computePacketChunkSize(dfsClient.getConf().writePacketSize, this.bytesPerChecksum);
    // 构造数据流对象
    this.streamer = new DFSOutputStream.DataStreamer(stat, this.addBlockFlags, (ExtendedBlock)null);
    if (favoredNodes != null && favoredNodes.length != 0) {
        this.streamer.setFavoredNodes(favoredNodes);
    }
}
```
首先计算数据包块大小，然后构造数据流对象，写HDFS文件的核心就是由该数据流对象DataStreamer，通过管道发送流式数据

## 2. 如何通过数据输出流写入数据？
### 2.1 DFSOutputStream输出流
DFSOutputStream内部封装了两个队列：发送数据包队列和确认数据包队列
``` java
// 发送数据包队列
private final LinkedList<DFSOutputStream.Packet> dataQueue;
// 确认数据包队列
private final LinkedList<DFSOutputStream.Packet> ackQueue;
```
客户端写入的数据，会addLast入发送数据包队列dataQueue，然后交给DataStreamer处理。

### 2.2 DataStreamer
DataStreamer类继承了Thread类，是一个线程。  
它负责在数据流管道中往DataNode发送数据包。它从NameNode申请获取一个新的数据块ID和数据块位置，然后开始往DataNode的管道写入流式数据包。每个数据包都有一个序列号sequence number。当一个数据块所有的数据包被发送出去，并且每个数据包的确认信息acks被接收到的话，DataStreamer关闭当前数据块，然后再向NameNode申请下一个数据块。

DataStreamer内部变量:  
**当前数据块构造阶段BlockConstructionStage stage**  
有如下阶段  
PIPELINE_SETUP_CREATE：管道初始化时向NameNode申请数据块及所在数据节点的状态  
DATA_STREAMING：正在流式写入的状态  
PIPELINE_SETUP_STREAMING_RECOVERY：发生异常  
PIPELINE_CLOSE：数据全部写完  
PIPELINE_SETUP_APPEND：管道初始化时向NameNode确定已有数据块及所在数据节点的状态  
PIPELINE_SETUP_APPEND_RECOVERY：发生异常

DataStreamer初始化时为create，则状态PIPELINE_SETUP_CREATE
初始化时为append，则状态PIPELINE_SETUP_APPEND

### 2.3 DataStreamer.run()方法
``` java
public void run() {
    //在数据流没有关闭，且dfs客户端正在运行的情况下，一直循环
    while(!this.streamerClosed && DFSOutputStream.this.dfsClient.clientRunning) {
        //如果遇到一个错误（hasErro），且响应器尚未关闭，关闭响应器，使之join等待；
        if (this.hasError && this.response != null) {
            try {
                this.response.close();
                this.response.join();
                this.response = null;
            } catch (InterruptedException var47) {
                DFSClient.LOG.warn("Caught exception ", var47);
            }
        }

        try {
            boolean doSleep = false;
            //如果有DataNode相关IO错误，先预先处理，初始化一些管道和流的信息，并决定外部是否等待，等待意即可以进行容错处理，不等待则数目错误比较严重，无法进行容错处理：
            //这里还判断了errorIndex标志位和restartingNodeIndex的大小，意思是是否是由某个具体数据节点引起的错误，如果是的话，这种错误理论上是可以处理的
            if (this.hasError && (this.errorIndex >= 0 || this.restartingNodeIndex >= 0)) {
                doSleep = this.processDatanodeError();
            }

            DFSOutputStream.Packet one;
            synchronized(DFSOutputStream.this.dataQueue) {
                //没有数据时，等待一个数据包发送
                //等待的条件是：当前流没有关闭(!streamerClosed)、没有错误（hasError）、dfs客户端正在 运行（dfsClient.clientRunning ）、dataQueue队列大小为0，且当前阶段不是DATA_STREAMING，或者在需要sleep（doSleep）或者上次发包距离本次时间未超过阈值的情况下为DATA_STREAMING
                for(long now = Time.now(); !this.streamerClosed && !this.hasError && DFSOutputStream.this.dfsClient.clientRunning && DFSOutputStream.this.dataQueue.size() == 0 && (this.stage != BlockConstructionStage.DATA_STREAMING || this.stage == BlockConstructionStage.DATA_STREAMING && now - lastPacket < (long)(DFSOutputStream.this.dfsClient.getConf().socketTimeout / 2)) || doSleep; now = Time.now()) {
                    long timeout = (long)(DFSOutputStream.this.dfsClient.getConf().socketTimeout / 2) - (now - lastPacket);
                    timeout = timeout <= 0L ? 1000L : timeout;
                    timeout = this.stage == BlockConstructionStage.DATA_STREAMING ? timeout : 1000L;

                    try {
                        DFSOutputStream.this.dataQueue.wait(timeout);
                    } catch (InterruptedException var46) {
                        DFSClient.LOG.warn("Caught exception ", var46);
                    }

                    doSleep = false;
                }
                //如果数据流关闭、存在错误、客户端正常运行标志位异常时，执行continue：这个应该是对容错等的处理，让程序及时响应错误；
                if (this.streamerClosed || this.hasError || !DFSOutputStream.this.dfsClient.clientRunning) {
                    continue;
                }

                //如果数据发送队列为空，构造一个心跳包；否则，取出队列中第一个元素，即待发送数据包。
                if (DFSOutputStream.this.dataQueue.isEmpty()) {
                    one = DFSOutputStream.this.createHeartbeatPacket();

                    assert one != null;
                } else {
                    try {
                        this.backOffIfNecessary();
                    } catch (InterruptedException var45) {
                        DFSClient.LOG.warn("Caught exception ", var45);
                    }

                    one = (DFSOutputStream.Packet)DFSOutputStream.this.dataQueue.getFirst();
                    SpanId[] parents = one.getTraceParents();
                    if (parents.length > 0) {
                        scope = DFSOutputStream.this.dfsClient.getTracer().newScope("dataStreamer", parents[0]);
                        scope.getSpan().setParents(parents);
                    }
                }
            }
            //如果当前阶段是PIPELINE_SETUP_CREATE，申请数据块，设置pipeline，初始化数据流：
            if (this.stage == BlockConstructionStage.PIPELINE_SETUP_CREATE) {
                if (DFSClient.LOG.isDebugEnabled()) {
                    DFSClient.LOG.debug("Allocating new block");
                }

                this.setPipeline(this.nextBlockOutputStream());
                this.initDataStreaming();
            } 
            //append的setup阶段则是通过setupPipelineForAppendOrRecovery()方法完成的，并同样会初始化数据流；
            else if (this.stage == BlockConstructionStage.PIPELINE_SETUP_APPEND) {
                if (DFSClient.LOG.isDebugEnabled()) {
                    DFSClient.LOG.debug("Append to block " + this.block);
                }

                this.setupPipelineForAppendOrRecovery();
                if (this.streamerClosed) {
                    continue;
                }

                this.initDataStreaming();
            }

            //获取数据块中的上次数据位置lastByteOffsetInBlock，如果超过数据块大小，报错；
            long lastByteOffsetInBlock = one.getLastByteOffsetBlock();
            if (lastByteOffsetInBlock > DFSOutputStream.this.blockSize) {
                throw new IOException("BlockSize " + DFSOutputStream.this.blockSize + " is smaller than data size. " + " Offset of packet in block " + lastByteOffsetInBlock + " Aborting file " + DFSOutputStream.this.src);
            }
            //如果是数据块的最后一个包：等待所有的数据包被确认，即等待datanodes的确认包acks
            if (one.lastPacketInBlock) {
                synchronized(DFSOutputStream.this.dataQueue) {
                    while(!this.streamerClosed && !this.hasError && DFSOutputStream.this.ackQueue.size() != 0 && DFSOutputStream.this.dfsClient.clientRunning) {
                        try {
                            DFSOutputStream.this.dataQueue.wait(1000L);
                        } catch (InterruptedException var44) {
                            DFSClient.LOG.warn("Caught exception ", var44);
                        }
                    }
                }
                //如果数据流关闭，或者数据节点IO存在错误，或者客户端不再正常运行，continue，设置阶段为pipeline关闭
                if (this.streamerClosed || this.hasError || !DFSOutputStream.this.dfsClient.clientRunning) {
                    continue;
                }

                this.stage = BlockConstructionStage.PIPELINE_CLOSE;
            }

            SpanId spanId = SpanId.INVALID;
            synchronized(DFSOutputStream.this.dataQueue) {
                if (!one.isHeartbeatPacket()) {
                    if (scope != null) {
                        spanId = scope.getSpanId();
                        scope.detach();
                        one.setTraceScope(scope);
                    }

                    scope = null;
                    DFSOutputStream.this.dataQueue.removeFirst();
                    DFSOutputStream.this.ackQueue.addLast(one);
                    DFSOutputStream.this.dataQueue.notifyAll();
                }
            }

            if (DFSClient.LOG.isDebugEnabled()) {
                DFSClient.LOG.debug("DataStreamer block " + this.block + " sending packet " + one);
            }

            TraceScope writeScope = DFSOutputStream.this.dfsClient.getTracer().newScope("DataStreamer#writeTo", spanId);

            //更新已发送数据大小：可以看出，数据包中存储了其在数据块中的位置LastByteOffsetBlock，也就标记了已经发送数据的总大小；
            try {
                one.writeTo(this.blockStream);
                this.blockStream.flush();
            } catch (IOException var42) {
                this.tryMarkPrimaryDatanodeFailed();
                throw var42;
            } finally {
                writeScope.close();
            }

            lastPacket = Time.now();
            long tmpBytesSent = one.getLastByteOffsetBlock();
            if (this.bytesSent < tmpBytesSent) {
                this.bytesSent = tmpBytesSent;
            }

            //数据块写满了吗？如果是最后一个数据块，等待确认包，调用endBlock()方法结束一个数据块 ；
            if (!this.streamerClosed && !this.hasError && DFSOutputStream.this.dfsClient.clientRunning) {
                if (one.lastPacketInBlock) {
                    synchronized(DFSOutputStream.this.dataQueue) {
                        while(!this.streamerClosed && !this.hasError && DFSOutputStream.this.ackQueue.size() != 0 && DFSOutputStream.this.dfsClient.clientRunning) {
                            DFSOutputStream.this.dataQueue.wait(1000L);
                        }
                    }

                    if (this.streamerClosed || this.hasError || !DFSOutputStream.this.dfsClient.clientRunning) {
                        continue;
                    }

                    this.endBlock();
                }

                if (DFSOutputStream.this.progress != null) {
                    DFSOutputStream.this.progress.progress();
                }

                if (DFSOutputStream.this.artificialSlowdown != 0L && DFSOutputStream.this.dfsClient.clientRunning) {
                    Thread.sleep(DFSOutputStream.this.artificialSlowdown);
                }
            }
        } catch (Throwable var52) {
            if (this.restartingNodeIndex == -1) {
                if (var52 instanceof QuotaExceededException) {
                    DFSClient.LOG.debug("DataStreamer Quota Exception", var52);
                } else {
                    DFSClient.LOG.warn("DataStreamer Exception", var52);
                }
            }

            if (var52 instanceof IOException) {
                this.setLastException((IOException)var52);
            } else {
                this.setLastException(new IOException("DataStreamer Exception: ", var52));
            }

            assert !(var52 instanceof NullPointerException);
            //如果上述流程发生错误，hasError标志位设置为true
            this.hasError = true;
            //如果不是一个DataNode引起的原因，流关闭标志设置为true
            if (this.errorIndex == -1 && this.restartingNodeIndex == -1) {
                this.streamerClosed = true;
            }
        } finally {
            if (scope != null) {
                scope.close();
                scope = null;
            }

        }
    }
    //没有数据需要发送，或者发生致命错误的情况下，调用closeInternal()方法关闭内部资源。
    this.closeInternal();
}
```
