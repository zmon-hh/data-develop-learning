# job提交的提交方式
## 1. 本地执行
这种方式无需启动或连接远程的集群

## 2. 集群上调用jar包
这种方式一般先将mr程序打成jar包，上传到集群里  
然后执行命令
``` sh
hadoop jar wc.jar WordCount
```
运行情况可以访问RM的web ui查看。

## 3. 连接到集群执行本地的jar包
方式1只是本地调试模式，方式2的缺点也很明显，当jar包带有依赖时，通常比较大，上传需要时间，所以当需要用集群进行调试时，方式3比较方便。

但用这种方式有些坑，故在此记录。

### 步骤 
#### 1.搭建本地hadoop环境
下载编译过的hadoop包，并且将其bin目录配到环境变量中
#### 2.更改core-site，yarn-site，mapred-site的xml文件
这里需要更改的xml有两个地方，一个是mr项目里的resources目录下的xml（或者直接用conf.set更改几个关键参数），另一个是本地hadoop环境etc目录下的xml。  

core-site.xml
``` xml
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://host001:8020</value>
  </property>
</configuration>
```
yarn-site.xml
``` xml
<configuration>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>host002</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>host002:8032</value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>host002:8030</value>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>host002:8031</value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>host002:8033</value>
  </property>
  <property>
    <name>yarn.application.classpath</name>
    <value>classpath值</value>
  </property>
</configuration>
```
这里classpath值通过在集群里使用命令
```sh
hadoop classpath
```
将返回结果的‘:’替换为‘,’后，复制进去。

mapred-site.xml
``` xml
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.address</name>
    <value>host002:10020</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>host002:19888</value>
  </property>
  <property>
    <name>yarn.app.mapreduce.am.resource.mb</name>
    <value>1024</value>
  </property>
  <property>
    <name>mapreduce.app-submission.cross-platform</name>
    <value>true</value>
  </property>
  <property>
    <name>mapred.remote.os</name>
    <value>Linux</value>
    <description>Remote MapReduce framework's OS, can be either Linux or Windows</description>
  </property>

</configuration>
```

#### 3. 修改mr工程maven的pom.xml
``` xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-shade-plugin</artifactId>
    <version>3.0.0</version>
    <executions>
        <!-- Run shade goal on package phase -->
        <execution>
            <phase>package</phase>
            <goals>
                <goal>shade</goal>
            </goals>
            <configuration>
                <filters>
                    <filter>
                        <!-- Do not copy the signatures in the META-INF folder.
                        Otherwise, this might cause SecurityExceptions when using the JAR. -->
                        <artifact>*:*</artifact>
                        <excludes>
                            <exclude>META-INF/*.SF</exclude>
                            <exclude>META-INF/*.DSA</exclude>
                            <exclude>META-INF/*.RSA</exclude>
                            <exclude>META-INF/LICENSE*</exclude>
                            <exclude>license/*</exclude>
                        </excludes>
                    </filter>
                </filters>
            </configuration>
        </execution>
    </executions>
</plugin>
```

#### 4.1 在ide中直接运行main执行
需要先将mr工程打包成jar包(wc.jar)，并在工程中加入一个配置参数 conf.set(“mapreduce.job.jar”,”wc.jar”);

#### 4.2 在本地cmd或powershell中执行
使用命令
然后执行命令
``` sh
hadoop jar wc.jar WordCount
```


### 问题
#### 1.Exception message: /bin/bash: 第 0 行:fg: 无任务控制
``` java
Exit code: 1
Exception message: /bin/bash: 第 0 行:fg: 无任务控制

Stack trace: ExitCodeException exitCode=1: /bin/bash: 第 0 行:fg: 无任务控制

    at org.apache.hadoop.util.Shell.runCommand(Shell.java:972)
    at org.apache.hadoop.util.Shell.run(Shell.java:869)
    at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1170)
    at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236)
    at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305)
    at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748)
```

需要加这个跨平台提交的参数
        conf.set("mapreduce.app-submission.cross-platform","true");

#### 2.错误: 找不到或无法加载主类org.apache.hadoop.mapreduce.v2.app.MRAppMaster

修改yarn-site.xml中的yarn.application.classpath值为集群的绝对classpath

#### 3.错误：Exception in thread "main" java.io.IOException: Mkdirs failed to create
``` java
Exception in thread "main" java.io.IOException: Mkdirs failed to create /var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/hadoop-unjar3745345762036287746/license
	at org.apache.hadoop.util.RunJar.ensureDirectory(RunJar.java:128)
	at org.apache.hadoop.util.RunJar.unJar(RunJar.java:104)
	at org.apache.hadoop.util.RunJar.unJar(RunJar.java:81)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:209)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
```

修改mr项目maven的pom配置，如步骤3

